{
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "eob5DzDhublc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30761,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "1ngKDvhltxpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU gradio diffusers transformers accelerate"
      ],
      "metadata": {
        "id": "-lnwKBrecHU0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command uses **pip**, Python's package installer, to install or upgrade four specific Python libraries from within a notebook environment like Jupyter or Google Colab.\n",
        "\n",
        "---\n",
        "\n",
        "## Command Breakdown\n",
        "\n",
        "* **`!`**: This prefix allows you to run a shell command directly in a code cell.\n",
        "* **`pip install`**: This is the core command to install Python packages.\n",
        "* **`-q`**: This flag stands for **quiet**. It reduces the amount of text output during installation, showing only essential information like errors.\n",
        "* **`-U`**: This flag stands for **upgrade**. It ensures that if the packages are already installed, they are upgraded to the latest available versions.\n",
        "\n",
        "---\n",
        "\n",
        "## Libraries Being Installed\n",
        "\n",
        "The command installs the following four libraries, which are commonly used for machine learning and AI applications, particularly with models from Hugging Face:\n",
        "\n",
        "1.  **`gradio`**: A library for quickly creating simple web-based user interfaces (UIs) for your machine learning models, making them easy to test and share.\n",
        "2.  **`diffusers`**: Provides tools and pre-trained models for creating images and audio from text descriptions, based on a technique called diffusion.\n",
        "3.  **`transformers`**: A foundational library that gives access to a vast collection of pre-trained models for tasks like text summarization, translation, and question answering.\n",
        "4.  **`accelerate`**: A utility that simplifies running PyTorch code on different hardware setups, such as multiple GPUs or TPUs, without needing to write complex code."
      ],
      "metadata": {
        "id": "4YRlKL-sttpE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import itertools\n",
        "import os\n",
        "from random import sample\n",
        "\n",
        "# Third-party imports\n",
        "import gradio as gr\n",
        "import torch\n",
        "from diffusers import FluxPipeline\n",
        "from IPython.display import Image"
      ],
      "metadata": {
        "id": "8Qat0l04ttpF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports various Python libraries and specific functions. The imports are organized into two groups: standard Python libraries and specialized third-party libraries.\n",
        "\n",
        "---\n",
        "\n",
        "## Standard Library Imports\n",
        "\n",
        "These modules are part of Python's built-in collection of tools.\n",
        "\n",
        "* `import itertools`: Imports a module that provides functions for creating complex loops and combinations of data in an efficient way.\n",
        "* `import os`: Imports a module that allows the program to interact with the operating system, for tasks like managing files and directories.\n",
        "* `from random import sample`: Imports the `sample` function from the `random` module. This function is used to select a specific number of unique, random items from a list or sequence.\n",
        "\n",
        "---\n",
        "\n",
        "## Third-Party Imports\n",
        "\n",
        "These are external libraries that must be installed separately and are commonly used in the field of AI and data science.\n",
        "\n",
        "* `import gradio as gr`: Imports the **Gradio** library, which is used to build and share simple web-based user interfaces for machine learning models. It's aliased as `gr` for easier use.\n",
        "* `import torch`: Imports **PyTorch**, a major deep learning framework that provides tools for building and training neural networks, especially with GPU acceleration.\n",
        "* `from diffusers import FluxPipeline`: Imports the `FluxPipeline` class from the **Diffusers** library. This library, created by Hugging Face, specializes in diffusion models, which are state-of-the-art for generating high-quality images from text descriptions. `FluxPipeline` is a specific tool for running the FLUX image generation model.\n",
        "* `from IPython.display import Image`: Imports the `Image` class, which is used specifically within environments like Jupyter Notebooks or Google Colab to display images directly in the output of a code cell."
      ],
      "metadata": {
        "id": "IFvf4GfQttpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    model = \"black-forest-labs/FLUX.1-dev\"\n",
        "    device = 'cuda'\n",
        "    dtype = torch.bfloat16\n",
        "    variant = \"fp16\"\n",
        "    howmany = 1 # nof images per prompt\n",
        "    seed = 42\n",
        "    infsteps = 30\n",
        "\n",
        "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
      ],
      "metadata": {
        "id": "e90RpkiyuXXJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a configuration class and sets an environment variable to prepare for running a machine learning model, specifically an image generation model from Hugging Face.\n",
        "\n",
        "---\n",
        "\n",
        "## Configuration Class (`CFG`)\n",
        "\n",
        "The code creates a class named `CFG` to act as a container for all the settings and parameters for the script. This practice keeps all the important variables organized and easy to modify in one place.\n",
        "\n",
        "* `model`: Specifies the **model identifier** on the Hugging Face Hub. Here, it's set to `\"black-forest-labs/FLUX.1-dev\"`, which is a specific version of the FLUX image generation model.\n",
        "* `device`: Sets the computation device to `'cuda'`, which means the program will use an NVIDIA GPU for processing. This is essential for accelerating the performance of deep learning models.\n",
        "* `dtype`: Sets the **data type** for the model's tensors to `torch.bfloat16`. This is a 16-bit floating-point format that reduces memory usage and speeds up calculations compared to the standard 32-bit float, while maintaining good numerical precision.\n",
        "* `variant`: Specifies that the `fp16` (16-bit floating point) version of the model weights should be downloaded. This reduces the download size.\n",
        "* `howmany`: A custom setting to generate **1 image** per prompt.\n",
        "* `seed`: Sets the **random seed** to `42`. Using a specific seed makes the image generation process reproducible, meaning the same input will always create the exact same output.\n",
        "* `infsteps`: Defines the number of **inference steps** as `30`. For diffusion models, this controls how many refinement steps are taken to generate the final image. A higher number can improve quality but takes more time.\n",
        "\n",
        "---\n",
        "\n",
        "## Environment Variable\n",
        "\n",
        "* `os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"`: This line modifies an **environment variable** for the operating system. By setting `HF_HUB_ENABLE_HF_TRANSFER` to `\"1\"`, it activates a faster, multi-threaded library for downloading files from the Hugging Face Hub. This significantly speeds up the initial model download."
      ],
      "metadata": {
        "id": "OVJPg_9rw972"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fix randomness\n",
        "g = torch.Generator(device = CFG.device).manual_seed(CFG.seed)"
      ],
      "metadata": {
        "id": "fyIXprSoC9uO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line creates a specific instance of a PyTorch random number generator to ensure that any operation involving randomness is reproducible.\n",
        "\n",
        "It works in two steps:\n",
        "\n",
        "1.  **`torch.Generator(device = CFG.device)`**: This creates a **Generator** object. Instead of using a global random state, this object manages its own sequence of random numbers. The `device = CFG.device` part is crucial, as it places the generator on the GPU (`'cuda'`). This ensures that random numbers used in GPU computations are controlled by this specific generator.\n",
        "\n",
        "2.  **`.manual_seed(CFG.seed)`**: This method sets the starting point for the random number sequence to a specific value, which is `42` as defined in the `CFG` class. By setting this **seed**, the sequence of numbers the generator produces will be exactly the same every time the code is run.\n",
        "\n",
        "When this generator `g` is passed to a function that has a random component (like creating the initial noise for an image), it guarantees the output will be identical across multiple runs."
      ],
      "metadata": {
        "id": "PE6wlpaDC-JQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "eob5DzDhublc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image(prompt):\n",
        "    image = pipe(\n",
        "      prompt=prompt, guidance_scale= 3.5,\n",
        "      height=768, width=1360,\n",
        "      num_inference_steps= CFG.infsteps,).images[0]\n",
        "    return image"
      ],
      "metadata": {
        "id": "nDqM4aKoucvi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a Python function named `create_image` that generates a single image based on a text description. The function takes one argument:\n",
        "* `prompt`: A string of text that describes the desired image content. 📝\n",
        "\n",
        "---\n",
        "\n",
        "## Process\n",
        "\n",
        "1.  **`pipe(...)`**: The function calls an object named `pipe`, which is the image generation pipeline (in our instance `FluxPipeline`). It passes several settings to control the generation process:\n",
        "    * **`prompt=prompt`**: The user's text description is passed directly to the model.\n",
        "    * **`guidance_scale=3.5`**: This value controls how strictly the model adheres to the prompt. A moderate value like 3.5 balances creativity with following instructions.\n",
        "    * **`height=768, width=1360`**: These set the dimensions of the output image to 1360x768 pixels, a widescreen format.\n",
        "    * **`num_inference_steps=CFG.infsteps`**: It uses the number of inference steps (`30`) defined earlier in the `CFG` configuration class.\n",
        "\n",
        "2.  **`.images[0]`**: The pipeline returns its output in a list format, even if it only generates one image. This code selects the very first item from that list.\n",
        "\n",
        "3.  **`return image`**: The function returns the final generated image object."
      ],
      "metadata": {
        "id": "Eu7Iyfx0ud2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplikacja"
      ],
      "metadata": {
        "id": "hg90frTVur1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = FluxPipeline.from_pretrained(CFG.model, torch_dtype = CFG.dtype)\n",
        "pipe.enable_model_cpu_offload()"
      ],
      "metadata": {
        "id": "89WXwgwhBxvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads a pre-trained image generation model and then applies a memory-saving optimization to it.\n",
        "\n",
        "---\n",
        "\n",
        "## Loading the Pre-trained Model\n",
        "\n",
        "`pipe = FluxPipeline.from_pretrained(CFG.model, torch_dtype = CFG.dtype)`\n",
        "\n",
        "This line downloads and initializes the image generation model.\n",
        "\n",
        "* **`FluxPipeline.from_pretrained(...)`**: This is a command from the `diffusers` library that loads a model that has already been trained.\n",
        "* **`CFG.model`**: It uses the model identifier (`\"black-forest-labs/FLUX.1-dev\"`) specified in the `CFG` class to find and download the correct model from the Hugging Face Hub.\n",
        "* **`torch_dtype = CFG.dtype`**: It instructs the library to load the model's parameters using the `torch.bfloat16` data type. This reduces the model's memory footprint and can speed up calculations.\n",
        "\n",
        "The fully loaded and configured model is then assigned to the variable `pipe`.\n",
        "\n",
        "---\n",
        "\n",
        "## Optimizing for Memory\n",
        "\n",
        "`pipe.enable_model_cpu_offload()`\n",
        "\n",
        "This line enables an optimization called **CPU offloading**. When a model is too large to fit entirely into the GPU's memory (VRAM), this function allows the system to intelligently shuttle parts of the model between the GPU and the main system RAM.\n",
        "\n",
        "Only the specific components needed for a given computation step are moved to the GPU, while the rest wait on the CPU. This allows you to run very large models on hardware with limited VRAM."
      ],
      "metadata": {
        "id": "QqATb_EPttpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(fn=create_image, inputs=\"text\", outputs=\"image\")\n",
        "\n",
        "demo.launch(debug = True)"
      ],
      "metadata": {
        "id": "OMq3xg6NBtCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the **Gradio** library to create and run a simple web-based user interface for the `create_image` function.\n",
        "\n",
        "---\n",
        "\n",
        "## Creating the User Interface\n",
        "\n",
        "`demo = gr.Interface(fn=create_image, inputs=\"text\", outputs=\"image\")`\n",
        "\n",
        "This line builds the web interface.\n",
        "\n",
        "* **`gr.Interface(...)`**: This is the primary function from the Gradio library for creating a UI.\n",
        "* **`fn=create_image`**: It specifies that the `create_image` function will be the backend logic. When a user enters something in the UI, this function is the one that gets called.\n",
        "* **`inputs=\"text\"`**: This tells Gradio to create a **text box** as the input field, so a user can type in their prompt.\n",
        "* **`outputs=\"image\"`**: This tells Gradio to create an **image component** to display the result returned by the `create_image` function.\n",
        "\n",
        "The complete, configured UI object is then stored in the `demo` variable.\n",
        "\n",
        "---\n",
        "\n",
        "## Launching the Web App\n",
        "\n",
        "`demo.launch(debug = True)`\n",
        "\n",
        "This line starts the web server, making the user interface accessible.\n",
        "\n",
        "* **`demo.launch()`**: This method activates the UI and generates a local URL. You can open this URL in your web browser to interact with the image generation model.\n",
        "* **`debug = True`**: This optional parameter runs the application in debug mode. If any errors occur while the app is running, it will provide more detailed error messages, which is very useful for troubleshooting."
      ],
      "metadata": {
        "id": "FWgt7JpXttpG"
      }
    }
  ]
}